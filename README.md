# comp130- Can you program SDV's to have "ethics"?

## Section 1 - Introduction
SDV(Self-Driving Vehicles) technology has come a long way since it's early beginnings in the 90's, with paper 4 documenting "challenges" that teams such as ARGO and Navlab demonstrating "thousands of kilometres of highway driving at speeds up to 130 kph with normal traffic" [4]. Although this may sound very much like what current SDV's are capable of in retrospect, the technology used was all far too large and took up most of the room in the car that could be used to possibly seat passengers,  and the route the cars took were pre-planned with "highly accurate GPS waypoints"[4] so this sort of test doesn't really have any sort of practicality in the real world and was more used to show that the technology could work, along with that all other cars and vehicles were removed from the course, with this paper, it's easy to see how far SDV's have come since their rather primoridal beginnings. However, thanks however to the continued miniaturisation of technology and the use of new technologies such as ultra high resolution cameras that can help spot pedestrians up to 97 meters away [6], (which can far outstrip that of some road users). SDV's are now something that is available to the general public, thanks in no small part to Tesla, who in 2015 allowed it's users to utilise the experimental "Autopilot" mode [3], and as such many other companies such as Google and the car giant Toyota started to invest and develop in SDV technology, but this sudden development didn't come without it's critiques, as the normal person and academics alike started to ask, can you program a SDV to have acceptable ethics?, and who is at fault when the vehicle makes a mistake?

## Section 2 - The Problems
As with any problem, there is a good outcome and a bad outcome, but what about the problems where there is no good outcome, this kind of problem is normally shown with the age old "Trolley" Problem where "in which a trolley is threatening to collide with unsuspecting children and the only way to stop it is to throw a fat man over the side of a bridge and onto the track's switch" [1] and as humans, we'll take many factors and our own morals into making this decision, where every individual's answer will be different, where as "because computer programs take things quite literally"[1], as paper 1 puts it, SDV's don't have the luxury of a human brain at their disposal, paper one also discusses that there have been many experiments and "substantial" literature on the subject, with paper 7 being one of them, where they ran a simulation of the "Trolley" problem and made test subjects pick an option depending on scenario, these included hitting once child, multiple children and their best friend, and then changed other factors such as their chance of survival, and obviously as the chance increased, they would pick to risk their life and save the other party over their own. People also seemed to pick saving children over old people by quite a surprising margin, which is something that another paper brought up, paper 2 brings up this with the situation of 2 old people and child crossing the road and the car can't dodge either, this is another moral dilemma that would the driver of a normal car would make based on their own morals and ethics, but what about an SDV? As discussed before, they can't decide on their own, so a programmer must make this decision by picking which is the option SDV will pick, so in a fatal collision, who is at fault and who will take the brunt of the aftermath?

## Section 3 - The Programmer or Driver, who is at fault?
Nearly all of the papers that I read discussed the section title in some way, paper 5 has quite an interesting view on the subject as it proposes a solution to the problem where by the SDV observes the drivers inputs and then changes and adapts it's own actions based on these inputs when it isn't in "Autopilot", meaning it will be the "driver's" actions at fault and not that of the SDV, subverting blame away from that that of programmer. Although this might be a good idea in theory, it wouldn't really work in real world as what happens if the SDV is put in a situation the driver has encountered yet?, then it will be down to the SDV's decision, which just spins it all back onto the programmer again; paper 5's solution is further compromised by the fact that the according to paper 3, the SDV's manufacturer, under current US law, will most likely take the blame anyway, which was quite surprising to me as I thought they would rather go after the driver as it would be more cost effective and waste less time, so in retrospective of that paper 5's solution has good intentions of bringing the blame away from the programmer and onto the SDV operator/driver, but the current justice system isn't built for SDV's, it's made for normal car's and normal human drivers, making it's main point overall redundant, and as paper 1 states "the law relies on a driver's common sense"[1], paper 1 seems to , which brings me onto my final next interesting finding which is the roads that these SDV's must travel on. 

## Section 4 - The Modern Driving Environment
SDV's thus far have had to be adapted and created around today's roads, with table 2 in paper 6 showing all of the sensors that are needed to enable the SDV to function on roads built for human drivers, such as being able to detect what position traffic lights are in, or if there is a level crossing barrier that has been lowered, or the most common barrier being road markings, but cameras in my eyes have a weakness, what happens if glare from the sun blocks out the light of the traffic light?, and although paper 6 is more of a technical document rather than that of opinion, other sources pointed out problems with these existing systems, such as paper 2 so aptly puts it "However, even with a full spectrum of technologies, if a city is not technologically-outfitted for SDVs, SDVs will not be able to drive properly." [2] Which is very interesting, but once you take all of the outside factors that can affect the SDV's ability to sense and see the world around it such as road markings might be very feint and not be picked up, and as these inputs us as humans use to make life or death situations on the road so of course they are integral to that of an SDV's ability to make "ethical" decisions on the road, which is why cities and large towns will be needed to upgrade their traffic control systems to suit the requirements of SDV's, such as what paper 3 suggests where traffic lights should be fitted with transmitter that allow the car to sense what position the lights are in rather than use the cameras which could be "struggling with shadows and glare"[3]; which is a very good idea to speed up the roll out of SDV's as a consumer product. 

## Source Aims and Conclusion
With the sources I picked, none of them seem to have an overall stance or if SDV's are bad or good, Sources 1 and 5 primary points seem to draw out the problems that SDV's currently have, and then propose ways in which these problems could be fixed or improved, which is helpful to developers of these vehicles, paper 3 is very much the same but just outlines where SDV's could come under scrutiny in law terms and again points out how they could be improved to get around these issues. Paper 4 mearly outlines early SDV technology but is still helpful to see how far they've come since then, while Paper 6 goes much further in depth about the workings of SDV's and was useful for drawing conclusions about the current technology that is used in SDV's to further my conclusions. And paper 7 was useful as it outlines human ethical decisions in scenarios that SDV's would be put in.


To conclude, all of the sources I have covered here do lend something to the conclusions that I have drawn over the course of my journal, I do think that SDV's have the capacity to make human-like "ethical" decisions but manufacturers will have to incorporate a number of the systems proposed in some of these papers and other that are being developed to make a SDV fully capable of making it's own decisions, along with the fact that the entire road system will need to be reworked for them, to make them function flawlessly it will be a long and expensive process, but I think one that is worth waiting for when looking at the number of lives that could be saved, as stated in paper 3 up to 30,000 lives a year in the United States alone could be saved by SDV's technology[3].



# Sources
## Paper 1: Can you program ethics into a self-driving car? Noah J. Goodall - cited
http://ieeexplore.ieee.org.ezproxy.falmouth.ac.uk/document/7473149/

## Paper 2:Driving the self-driving vehicle: Expanding the technological design horizon Pascale-L. Blyth - cited
http://ieeexplore.ieee.org.ezproxy.falmouth.ac.uk/document/7439419/

## Paper 3:Self-driving cars and the law Nathan A. Greenblatt - cited
http://ieeexplore.ieee.org.ezproxy.falmouth.ac.uk/document/7419800/

## Paper 4 :Self-Driving Cars and the Urban Challenge Chris Urmson - cited
http://ieeexplore.ieee.org.ezproxy.falmouth.ac.uk/document/4475861/

## Paper 5:Issues about autonomous cars Claudiu Pozna - cited            
http://ieeexplore.ieee.org.ezproxy.falmouth.ac.uk/document/7507360/

## Paper 6:An Autonomous Driving System for Unknown Environments Using a Unified Map View Document Inwook Shim - cited
http://ieeexplore.ieee.org.ezproxy.falmouth.ac.uk/document/7046370/

## Paper 7:First Person Trolley Problem: Evaluation of Drivers' Ethical Decisions in a Driving Simulator - cited
http://delivery.acm.org.ezproxy.falmouth.ac.uk/10.1145/3010000/3004336/p117-frison.pdf?ip=193.61.64.8&id=3004336&acc=ACTIVE%20SERVICE&key=BF07A2EE685417C5%2EEAA225A8AB01C582%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=727941429&CFTOKEN=73815547&__acm__=1490977716_858b57fdc01d85585787b0565d9ada65

